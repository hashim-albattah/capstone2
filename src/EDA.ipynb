{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from PIL import Image\n",
    "# sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Image\n",
    "# print(Image.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/galvanize/capstones/capstone_2/capstone2/src\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U numpy\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=2397 sha256=0cf3275f2a6460c70212ee9798dd8e9893958e8c4cab6820ff2e0e8ac958dcfc\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scipy, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.2.0)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.5.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.3.2)\n",
      "Collecting networkx>=2.0\n",
      "  Downloading networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.18.5)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Installing collected packages: imageio, tifffile, networkx, PyWavelets, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 imageio-2.9.0 networkx-2.5 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b51268bac2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8b7580fab5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7168)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec  3 18:15:42 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.38       Driver Version: 455.38       CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 207...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   45C    P0    21W /  N/A |    652MiB /  7982MiB |      6%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (3.3.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: six in /home/hash/anaconda3/envs/tf/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "#!/usr/bin/env python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zappostesttrain_dir = '../data/ut-zap50k-data/train-test-splits'\n",
    "# x = loadmat(zappostesttrain_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index = x['trainIndexAll']\n",
    "# test_index = x['testIndexAll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapposimagepath_dir = '../data/ut-zap50k-data/image-path.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata = loadmat(zapposimagepath_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata.get('imagepath')[1000][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../data/ut-zap50k-data/ut-zap50k-images-square/Boots/7965307.5291.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.getpixel((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapposlabels_dir = '../data/ut-zap50k-data/zappos-labels.mat'\n",
    "# zapposlabels = loadmat(zapposlabels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(zapposlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapposlabels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build pipeline as if for one image, then extend it with either function or class\n",
    "# class imagePipeline:\n",
    "#     def __init__(self,imagepath):\n",
    "#         self.imagepath = imagepath\n",
    "#         self.image = Image.open(imagepath)\n",
    "#     def as_array(self):\n",
    "#         return np.asarray(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_arrays = []\n",
    "# for i in imagepathdata.get('imagepath'):\n",
    "#     imagepath = '../data/ut-zap50k-data/ut-zap50k-images-square/' + i[0][0]\n",
    "#     image = imagePipeline(imagepath).as_array()\n",
    "#     img_arrays.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def sub_subfolder(mainpath,subpath,catlist): #subpath i.e. \"boot\" ... catlist = [over knee, etc...]\n",
    "    subs = []\n",
    "    for i in catlist:\n",
    "        folder = mainpath + subpath + i\n",
    "        subfolders = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "        for sub in subfolders:\n",
    "            for f in os.listdir(sub):\n",
    "                src = os.path.join(sub, f)\n",
    "                dst = os.path.join(folder, f)\n",
    "                shutil.move(src, dst)\n",
    "            shutil.rmtree(sub)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = '../data/ut-zap50k-data/ut-zap50k-images-square/'\n",
    "# bootcat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Boots')\n",
    "# sub_subfolder(main_path,'Boots/',bootcat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sandalcat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Sandals')\n",
    "# sub_subfolder(main_path,'Sandals/',sandalcat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shoecat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Shoes')\n",
    "# sub_subfolder(main_path,'Shoes/',shoecat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slippercat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Slippers')\n",
    "# sub_subfolder(main_path,'Slippers/',slippercat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path2 = '../data/ut-zap50k-data/'\n",
    "# imagescat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square')\n",
    "# sub_subfolder(main_path2,'ut-zap50k-images-square/',imagescat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '../data/ut-zap50k-data/ut-zap50k-images-square/'\n",
    "# img_prepocessing = keras.preprocessing.image_dataset_from_directory(\n",
    "#     directory,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",\n",
    "#     class_names=None,\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=32,\n",
    "#     image_size=(256, 256),\n",
    "#     shuffle=True,\n",
    "#     seed=None,\n",
    "#     validation_split=None,\n",
    "#     subset=None,\n",
    "#     interpolation=\"bilinear\",\n",
    "#     follow_links=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_prepocessing.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '../data/ut-zap50k-data/ut-zap50k-images-square'\n",
    "# Cls_boots = '/Boots'\n",
    "# Cls_sandals = '/Sandals'\n",
    "# Cls_shoes = '/Shoes'\n",
    "# Cls_slippers = '/Slippers'\n",
    "# Cls_lst = [Cls_boots,Cls_sandals,Cls_shoes,Cls_slippers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(root_dir +'/train' + Cls_boots)\n",
    "# os.makedirs(root_dir +'/train' + Cls_sandals)\n",
    "# os.makedirs(root_dir +'/train' + Cls_shoes)\n",
    "# os.makedirs(root_dir +'/train' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(root_dir +'/val' + Cls_boots)\n",
    "# os.makedirs(root_dir +'/val' + Cls_sandals)\n",
    "# os.makedirs(root_dir +'/val' + Cls_shoes)\n",
    "# os.makedirs(root_dir +'/val' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(root_dir +'/test' + Cls_boots)\n",
    "# os.makedirs(root_dir +'/test' + Cls_sandals)\n",
    "# os.makedirs(root_dir +'/test' + Cls_shoes)\n",
    "# os.makedirs(root_dir +'/test' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in Cls_lst:\n",
    "#     src = \"../data/ut-zap50k-data/ut-zap50k-images-square\"+i # Folder to copy images from\n",
    "\n",
    "#     allFileNames = os.listdir(src)\n",
    "#     np.random.shuffle(allFileNames)\n",
    "#     train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "#                                                               [int(len(allFileNames)*0.7), int(len(allFileNames)*0.85)])\n",
    "#     train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "#     val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "#     test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "#     print('Total images: ', len(allFileNames))\n",
    "#     print('Training: ', len(train_FileNames))\n",
    "#     print('Validation: ', len(val_FileNames))\n",
    "#     # Copy-pasting images\n",
    "#     for name in train_FileNames:\n",
    "#         shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/train\"+i)\n",
    "#     for name in val_FileNames:\n",
    "#         shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/val\"+i)\n",
    "#     for name in test_FileNames:\n",
    "#         shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/test\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35020 images belonging to 4 classes.\n",
      "Found 7504 images belonging to 4 classes.\n",
      "Found 7507 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x7f839f9e1cf8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/train',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/val',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/test',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what loss functions / filters/ kernel size to use\n",
    "\n",
    "def define_model(kernel_size=(4,4), input_shape=[136,102,3], pool_size=2, nb_classes=4):\n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(32, (kernel_size[0], kernel_size[1]),\n",
    "                        padding='valid', \n",
    "                        input_shape=input_shape)) #first conv. layer\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Conv2D(64, (kernel_size[0], kernel_size[1]), padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size)) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "    model.add(Dense(32)) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = define_model()\n",
    "# model = keras.models.load_model(\"weights.37-0.810.hdf5\")\n",
    "# model.summary()\n",
    "input_shape=[136,102,3]\n",
    "model = Sequential([\n",
    "  keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=input_shape),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  keras.layers.MaxPooling2D(),\n",
    "  keras.layers.Dropout(0.2),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu'),\n",
    "  keras.layers.Dense(4)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir(root_logdir)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to need speficic steps for epochs, steps_per_epoch, validation_steps\n",
    "#look up early-stopping callback (to help set really high number for epochs so it stops once it reaches the best)\n",
    "\n",
    "checkpoint_filepath = './weights.{epoch:02d}-{accuracy:.3f}.hdf5'\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True, monitor = 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 136, 102, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 68, 51, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 68, 51, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 17, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13056)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1671296   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,695,396\n",
      "Trainable params: 1,695,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Relu (defined at <ipython-input-13-5793d6b6862a>:6) ]] [Op:__inference_train_function_940]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5793d6b6862a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         validation_steps=7504//32)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Relu (defined at <ipython-input-13-5793d6b6862a>:6) ]] [Op:__inference_train_function_940]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=35020//32,\n",
    "        epochs=1000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7504//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = np.array(list(test_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.argmax(y_hat, axis = 1)\n",
    "# y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx[np.argmax(y_hat, axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_generator.labels\n",
    "# y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_hat == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_true,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True')\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "# load the image\n",
    "img = load_img('../data/ut-zap50k-data/ut-zap50k-images-square/Sandals/102307.298.jpg')\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "# create image data augmentation generator\n",
    "#datagen = ImageDataGenerator(height_shift_range=0.5)\n",
    "# prepare iterator\n",
    "it = train_datagen.flow(samples, batch_size=1)\n",
    "# generate samples and plot\n",
    "pyplot.title(label='These waffles have bee height_shift_range=0.5,shear_range=0.2, zoom_range=0.2, horizontal_flip=True')\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot( 330 +1 +i)\n",
    "    # generate batch of images\n",
    "    batch = it.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0].astype('uint8')\n",
    "    # plot raw pixel data\n",
    "    pyplot.minorticks_off()\n",
    "    pyplot.imshow(image)\n",
    "    pyplot.axis('off')\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
