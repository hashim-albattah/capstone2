{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "#!/usr/bin/env python\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, color, filters\n",
    "from skimage.transform import resize, rotate\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zappostesttrain_dir = '../data/ut-zap50k-data/train-test-splits'\n",
    "# x = loadmat(zappostesttrain_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index = x['trainIndexAll']\n",
    "# test_index = x['testIndexAll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapposimagepath_dir = '../data/ut-zap50k-data/image-path.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata = loadmat(zapposimagepath_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagepathdata.get('imagepath')[1000][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open('../data/ut-zap50k-data/ut-zap50k-images-square/Boots/Ankle/A. Testoni/7965307.5291.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.getpixel((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zapposlabels_dir = '../data/ut-zap50k-data/zappos-labels.mat'\n",
    "zapposlabels = loadmat(zapposlabels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(zapposlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'mturkOrder', 'mturkEqual'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zapposlabels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build pipeline as if for one image, then extend it with either function or class\n",
    "# class imagePipeline:\n",
    "#     def __init__(self,imagepath):\n",
    "#         self.imagepath = imagepath\n",
    "#         self.image = Image.open(imagepath)\n",
    "#     def as_array(self):\n",
    "#         return np.asarray(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_arrays = []\n",
    "# for i in imagepathdata.get('imagepath'):\n",
    "#     imagepath = '../data/ut-zap50k-data/ut-zap50k-images-square/' + i[0][0]\n",
    "#     image = imagePipeline(imagepath).as_array()\n",
    "#     img_arrays.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "def sub_subfolder(mainpath,subpath,catlist): #subpath i.e. \"boot\" ... catlist = [over knee, etc...]\n",
    "    subs = []\n",
    "    for i in catlist:\n",
    "        folder = mainpath + subpath + i\n",
    "        subfolders = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
    "        for sub in subfolders:\n",
    "            for f in os.listdir(sub):\n",
    "                src = os.path.join(sub, f)\n",
    "                dst = os.path.join(folder, f)\n",
    "                shutil.move(src, dst)\n",
    "            shutil.rmtree(sub)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '../data/ut-zap50k-data/ut-zap50k-images-square/'\n",
    "bootcat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Boots')\n",
    "sub_subfolder(main_path,'Boots/',bootcat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandalcat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Sandals')\n",
    "sub_subfolder(main_path,'Sandals/',sandalcat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoecat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Shoes')\n",
    "sub_subfolder(main_path,'Shoes/',shoecat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "slippercat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square/Slippers')\n",
    "sub_subfolder(main_path,'Slippers/',slippercat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path2 = '../data/ut-zap50k-data/'\n",
    "imagescat_list = os.listdir('../data/ut-zap50k-data/ut-zap50k-images-square')\n",
    "sub_subfolder(main_path2,'ut-zap50k-images-square/',imagescat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50031 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/ut-zap50k-data/ut-zap50k-images-square/'\n",
    "img_prepocessing = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boots', 'Sandals', 'Shoes', 'Slippers']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_prepocessing.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../data/ut-zap50k-data/ut-zap50k-images-square'\n",
    "Cls_boots = '/Boots'\n",
    "Cls_sandals = '/Sandals'\n",
    "Cls_shoes = '/Shoes'\n",
    "Cls_slippers = '/Slippers'\n",
    "Cls_lst = [Cls_boots,Cls_sandals,Cls_shoes,Cls_slippers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(root_dir +'/train' + Cls_boots)\n",
    "os.makedirs(root_dir +'/train' + Cls_sandals)\n",
    "os.makedirs(root_dir +'/train' + Cls_shoes)\n",
    "os.makedirs(root_dir +'/train' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(root_dir +'/val' + Cls_boots)\n",
    "os.makedirs(root_dir +'/val' + Cls_sandals)\n",
    "os.makedirs(root_dir +'/val' + Cls_shoes)\n",
    "os.makedirs(root_dir +'/val' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(root_dir +'/test' + Cls_boots)\n",
    "os.makedirs(root_dir +'/test' + Cls_sandals)\n",
    "os.makedirs(root_dir +'/test' + Cls_shoes)\n",
    "os.makedirs(root_dir +'/test' + Cls_slippers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  12834\n",
      "Training:  8983\n",
      "Validation:  1925\n",
      "Total images:  5741\n",
      "Training:  4018\n",
      "Validation:  861\n",
      "Total images:  30173\n",
      "Training:  21121\n",
      "Validation:  4526\n",
      "Total images:  1283\n",
      "Training:  898\n",
      "Validation:  192\n"
     ]
    }
   ],
   "source": [
    "for i in Cls_lst:\n",
    "    src = \"../data/ut-zap50k-data/ut-zap50k-images-square\"+i # Folder to copy images from\n",
    "\n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)*0.7), int(len(allFileNames)*0.85)])\n",
    "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "    val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n",
    "    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "    print('Total images: ', len(allFileNames))\n",
    "    print('Training: ', len(train_FileNames))\n",
    "    print('Validation: ', len(val_FileNames))\n",
    "    # Copy-pasting images\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/train\"+i)\n",
    "    for name in val_FileNames:\n",
    "        shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/val\"+i)\n",
    "    for name in test_FileNames:\n",
    "        shutil.copy(name, \"../data/ut-zap50k-data/ut-zap50k-images-square/test\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35020 images belonging to 4 classes.\n",
      "Found 7504 images belonging to 4 classes.\n",
      "Found 7507 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/train',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/val',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../data/ut-zap50k-data/ut-zap50k-images-square/test',\n",
    "        target_size=(136, 102),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what loss functions / filters/ kernel size to use\n",
    "def define_model(nb_filters, kernel_size, input_shape, pool_size):\n",
    "    model = Sequential() # model is a linear stack of layers (don't change)\n",
    "    # note: the convolutional layers and dense layers require an activation function\n",
    "    # see https://keras.io/activations/\n",
    "    # and https://en.wikipedia.org/wiki/Activation_function\n",
    "    # options: 'linear', 'sigmoid', 'tanh', 'relu', 'softplus', 'softsign'\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                        padding='valid', \n",
    "                        input_shape=input_shape)) #first conv. layer  KEEP\n",
    "    model.add(Activation('relu')) # Activation specification necessary for Conv2D and Dense layers\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), padding='valid')) #2nd conv. layer KEEP\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size)) # decreases size, helps prevent overfitting\n",
    "    model.add(Dropout(0.5)) # zeros out some fraction of inputs, helps prevent overfitting\n",
    "    model.add(Flatten()) # necessary to flatten before going into conventional dense layer  KEEP\n",
    "    print('Model flattened out to ', model.output_shape)\n",
    "    # now start a typical neural network\n",
    "    model.add(Dense(32)) # (only) 32 neurons in this layer, really?   KEEP\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5)) # zeros out some fraction of inputs, helps prevent overfitting\n",
    "    model.add(Dense(nb_classes)) # 10 final nodes (one for each class)  KEEP\n",
    "    model.add(Activation('softmax')) # softmax at end to pick between classes 0-9 KEEP\n",
    "    \n",
    "    # many optimizers available, see https://keras.io/optimizers/#usage-of-optimizers\n",
    "    # suggest you KEEP loss at 'categorical_crossentropy' for this multiclass problem,\n",
    "    # and KEEP metrics at 'accuracy'\n",
    "    # suggest limiting optimizers to one of these: 'adam', 'adadelta', 'sgd'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to need speficic steps for epochs, steps_per_epoch, validation_steps\n",
    "#look up early-stopping callback (to help set really high number for epochs so it stops once it reaches the best)\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
